---
title: "Experiment 4 - choice analysis (complete dataset)"
author: 
  - name: "Zhang Chen"
    orcid: 0000-0002-3500-9182
date: "`r format(Sys.time(), '%d %B, %Y')`"
format: 
  html:
    code-fold: true
    code-tools: true
editor: visual
execute: 
  warning: false
  error: false
toc: true
toc-depth: 3
---

For this set of analyses, I use the complete dataset, combining data from both phases.

## Load libraries and data

```{r}
# load libraries
library(MASS)
library(Rmisc)
library(afex)
library(tidyverse)
library(ggpubr)

library(extraDistr)
library(loo)
library(bridgesampling)
library(brms)
library(cmdstanr)
library(bayesplot)
library(bayestestR)
library(tidybayes)
library(sjPlot)

# parallelize the chains using all the cores
options(mc.cores = parallel::detectCores())

# set the theme for all ggplot2 figures
theme_set(theme_bw() +
            theme(legend.position = "top",
                  legend.direction = "horizontal"))

# create a folder for saving brms fits
if(!dir.exists("brms-fits")){
  dir.create("brms-fits")
}

# load the cleaned data
df_main <- read_csv("../../../data/processed/df_main_exp4_complete.csv")
```

## Choices

### Catch trials

In this experiment, I included two types of catch trials, either the high-probability option or the low-probability option has a much higher expected value than the other. Here I plot how often participants chose the higher EV option for these two types of catch trials (@fig-catch-choice).

```{r}
#| label: fig-catch-choice
#| fig-cap: The proportion of choosing the high EV option on the catch trials when the high-probability option (top) or the low-probability option (bottom) has a higher EV.
#| fig-width: 7
#| fig-height: 5 

# catch trials
df_catch_choices <- df_main %>%
  filter(trial_type == "catch") %>%
  group_by(subject_ID, high_EV_option) %>%
  summarize(
    # the total number of trials, should be 12 for all participants
    n_total = n(),
    # the number of trials on which people chose the high EV option
    n_high_EV =  sum(choose_high_EV == "yes"),
    # the proportion of choosing the high EV option
    prop_high_EV = n_high_EV / n_total* 100
  ) %>%
  ungroup()

# plot the choices on the catch trials
ggplot(df_catch_choices, aes(subject_ID, prop_high_EV)) +
  geom_line(aes(group = 1), color = "gray") +
  geom_point() +
  labs(x = "Participant", 
       y = "The proportion of choosing high EV options") +
  facet_wrap(~high_EV_option, ncol = 1)

# compute some descriptives
catch_choices_descriptive <- df_catch_choices %>%
  group_by(high_EV_option) %>%
  summarize(
    mean = mean(n_high_EV),
    sd = sd(n_high_EV),
    min = min(n_high_EV),
    max = max(n_high_EV)
  )
```

### Experimental trials

#### EV ratios

In this analysis, I use the EV ratio between two options, the outcome of game 1 (loss = 0.5, win = -0.5) and whether there was a pause or not (yes = 0.5, no = -0.5) and their interactions as predictors to predict whether participants chose the HP option or not on each trial. I use the maximum random structure by including both random intercept and all random slopes per participant.

```{r}
# find the participants that need to be excluded,
# here I do not exclude any participants
low_prob_cutoff <- 0

subject_exclude <- df_catch_choices %>%
  filter(
    high_EV_option == "LP",
    n_high_EV < low_prob_cutoff
    ) %>% .$subject_ID

df_exp_selected <- df_main %>%
  filter(
    !subject_ID %in% subject_exclude,
    trial_type == "exp"
  )

# fit a brms model - go for the maximum random structure
brms_file_name <- 
  paste("brms-fits/fit_exp_LP", low_prob_cutoff, sep = "_")

fit_exp <- brm(
  game2_choose_HP ~ EV_ratio * game1_outcome_num * delay_num +
    (EV_ratio * game1_outcome_num * delay_num|subject_ID),
  family = bernoulli(link = "logit"),
  prior = 
    c(
      prior(normal(0, 2), class = Intercept),
      prior(normal(0, 1), class = b),
      prior(normal(0, 1), class = sd),
      prior(lkj(2), class = cor)
    ),
  data = df_exp_selected,
  cores = 4,
  iter = 15000,
  warmup = 5000,
  seed = 1234,
  file = brms_file_name,
  backend = "cmdstanr"
)

# save the data for later analysis
write_csv(df_exp_selected, 
          "../../../data/processed/df_exp_exp4_complete.csv")

```

Some general posterior predictive checks (@fig-ppc-general).

```{r}
#| label: fig-ppc-general
#| fig-cap: General posterior predictive checks.
#| fig-subcap: 
#| - "As a function of delay"
#| - "As a function of game 1 outcome"
#| - "As a function of EV ratio"
#| layout: [[1, 1], [1]]
#| fig-width: 8
#| fig-height: 8

# posterior predictive checks
yrep <- posterior_predict(fit_exp)

ppc_bars_grouped(df_exp_selected$game2_choose_HP, yrep, 
                 df_exp_selected$delay, prob = 0.95, freq = FALSE)

ppc_bars_grouped(df_exp_selected$game2_choose_HP, yrep, 
                 df_exp_selected$game1_outcome, prob = 0.95, freq = FALSE)

ppc_bars_grouped(df_exp_selected$game2_choose_HP, yrep, 
                 df_exp_selected$EV_ratio, prob = 0.95, freq = FALSE)
```

Make a plot to show the effects of EV ratio and delay.

```{r}
#| label: fig-EV-ratio-delay
#| fig-cap: Probability of choosing the HP option as a function of EV ratio and pause.
#| fig-width: 6
#| fig-height: 6

# Here I will plot the probability of choosing the HP option
# as a function of the EV ratio and whether there was a delay or not
# EV ratio will be the x axis, and delay (yes vs. no) as two colors
# here I define a small adjustment value to the x axis (i.e. EV ratio),
# that moves all no delay condition data points a bit to the left,
# and the delay condition data points to the right, to reduce overlapping.
x_adj_amount <- 0.025

# compute the probability of choosing HP for each participant
# in each condition.
plot_raw_data <- df_exp_selected %>%
  group_by(subject_ID, EV_ratio, delay) %>%
  summarize(p_HP = mean(game2_choose_HP)) %>%
  mutate(
    # add a bit adjustment as mentioned above
    EV_ratio_adj = ifelse(delay == "yes", x_adj_amount, -x_adj_amount),
    EV_ratio_plot = EV_ratio + EV_ratio_adj
  )

# get the predicted prob of choosing HP from brms
int_conds <- list(
  EV_ratio = unique(df_exp_selected$EV_ratio),
  delay_num = c(-0.5, 0.5)
)

plot_prediction <- 
  conditional_effects(
    fit_exp, 
    "EV_ratio:delay_num",
    int_conditions = int_conds)

# turn the predictions into a tibble
plot_pred <- as_tibble(
  plot_prediction$`EV_ratio:delay_num`
  ) %>%
  mutate(
    # similarly, add a little adjustment to the EV ratio
    delay = ifelse(delay_num == 0.5, "yes", "no"),
    EV_ratio_adj = ifelse(delay == "yes", x_adj_amount, -x_adj_amount),
    EV_ratio_plot = EV_ratio + EV_ratio_adj
  )

# plot the results
EV_delay_plot <- plot_raw_data %>%
  ggplot(aes(EV_ratio_plot, p_HP, color = delay)) +
  # plot raw data per participant as transparent open circles
  # jitter the dots vertically a bit to reduce overlapping
  geom_jitter(alpha = 0.2, height = 0.05, shape = 1) +
  # connect the predicted prob of choosing HP with lines
  geom_line(data = plot_pred, 
            aes(x = EV_ratio_plot,
                y = estimate__,
                group = delay),
            alpha = 0.4) +
  # estimates as solid points
  geom_point(data = plot_pred, 
             aes(EV_ratio_plot, 
                 estimate__)) +
  # add 95% CI as error bars
  geom_errorbar(data = plot_pred,
                aes(x = EV_ratio_plot, 
                    y = estimate__,
                    ymin = lower__, 
                    ymax = upper__),
                width = 0.05) +
  labs(x = "EV ratio", 
       y = "P(Choose the HP option)",
       color = "Pause")

EV_delay_plot

# save as a png file
ggsave(filename = "../5-plots/EV_delay_Exp4_complete.png", 
       EV_delay_plot,
       width = 4, height = 4)
```

Make a similar plot, but this time also take the previous outcome into account.

```{r}
#| label: fig-EV-ratio-delay-outcome
#| fig-cap: Probability of choosing the HP option as a function of EV ratio, pause, and previous outcome.
#| fig-width: 7
#| fig-height: 5

source("function/choice_plot_functions.R")

# select parameters of interest
var_selected <- get_variables(fit_exp)[1:8]

# get posterior draws for these parameters
draws <- fit_exp %>% as_draws_df(variable = var_selected) 

choice_params_plot <- plot_choice_params(draws)

choice_plots <- plot_choice(draws)

choice_pause_outcome_plot <- choice_plots$p1

choice_pause_outcome_plot

# save the plot as an RDS file, will be combined with plots from other exps
saveRDS(choice_pause_outcome_plot, "../plots/choice_plot_exp4.rds")
```

```{r, results='asis'}
tab_model(fit_exp)
```

### High EV choices

In this exploratory analysis, I analyze the probability of choosing the high EV option as a function of previous outcome, pause, and whether the high EV option was a HP or a LP option.

```{r}
df_exp_selected <- df_exp_selected %>%
  mutate(
    high_EV_option_num = ifelse(high_EV_option == "HP", 0.5, -0.5),
    choose_high_EV_num = ifelse(choose_high_EV == "yes", 1, 0)
  )

fit_high_EV <- brm(
  choose_high_EV_num ~ game1_outcome_num * delay_num * high_EV_option_num +
    (game1_outcome_num * delay_num * high_EV_option_num|subject_ID),
  family = bernoulli(link = "logit"),
  prior = 
    c(
      prior(normal(0, 2), class = Intercept),
      prior(normal(0, 1), class = b),
      prior(normal(0, 1), class = sd),
      prior(lkj(2), class = cor)
    ),
  data = df_exp_selected,
  cores = 4,
  iter = 15000,
  warmup = 5000,
  seed = 1234,
  file = "brms-fits/fit_high_EV",
  backend = "cmdstanr"
  # , control = list(adapt_delta = 0.9)
)
```

```{r, results='asis'}
tab_model(fit_high_EV)
```

### Prob and amount

```{r}
# compute the prob ratio and amount ratio between two options
df_exp_selected <- df_exp_selected %>%
  mutate(
    prob_ratio = (game2_HP_prob - game2_LP_prob)/(game2_HP_prob + game2_LP_prob) * 2,
    amount_ratio = (game2_HP_amount - game2_LP_amount)/(game2_HP_amount + game2_LP_amount) * 2
  )

# get the unique trials and compute the mean prob_ratio and amount_ratio
df_unique <- df_exp_selected %>%
  select(game2_HP_prob, game2_HP_amount, game2_LP_prob, game2_LP_amount, prob_ratio, amount_ratio) %>%
  unique()

prob_ratio_mean <- mean(df_unique$prob_ratio)
amount_ratio_mean <- mean(df_unique$amount_ratio)

# center the prob_ratio and amount_ratio predictors
df_exp_selected <- df_exp_selected %>%
  mutate(
    prob_ratio_centered = prob_ratio - prob_ratio_mean,
    amount_ratio_centered = amount_ratio - amount_ratio_mean
  )

# fit a brms model
brms_file_name <- "brms-fits/fit_prob_amount"

fit_prob_amount <- brm(
  game2_choose_HP ~ prob_ratio_centered * amount_ratio_centered *
                    game1_outcome_num * delay_num +
                    (prob_ratio_centered * amount_ratio_centered *
                    game1_outcome_num * delay_num|subject_ID),
  family = bernoulli(link = "logit"),
  prior = 
    c(
      prior(normal(0, 2), class = Intercept),
      prior(normal(0, 1), class = b),
      prior(normal(0, 1), class = sd),
      prior(lkj(2), class = cor)
    ),
  data = df_exp_selected,
  cores = 4,
  iter = 15000,
  warmup = 5000,
  seed = 1234,
  file = brms_file_name,
  backend = "cmdstanr"
)
```

```{r}
#| label: fig-ppc-general-2
#| fig-cap: General posterior predictive checks.
#| fig-subcap: 
#| - "As a function of delay"
#| - "As a function of game 1 outcome"
#| - "As a function of EV ratio"
#| layout: [[1, 1], [1]]
#| fig-width: 8
#| fig-height: 8

# posterior predictive checks
yrep <- posterior_predict(fit_prob_amount)

ppc_bars_grouped(df_exp_selected$game2_choose_HP, yrep, 
                 df_exp_selected$delay, prob = 0.95, freq = FALSE)

ppc_bars_grouped(df_exp_selected$game2_choose_HP, yrep, 
                 df_exp_selected$game1_outcome, prob = 0.95, freq = FALSE)

ppc_bars_grouped(df_exp_selected$game2_choose_HP, yrep, 
                 df_exp_selected$EV_ratio, prob = 0.95, freq = FALSE)
```

```{r}
var_selected <- get_variables(fit_prob_amount)[1:16]

draws <- fit_prob_amount %>%
  as_draws_df(variable = var_selected) %>%
  pivot_longer(cols = all_of(var_selected),
               names_to = "parameter",
               values_to = "estimate") %>%
  mutate(parameter = 
           factor(parameter, levels = var_selected,
                  labels = c("Intercept",
                             "Probability",
                             "Amount",
                             "Prev outcome (loss vs. win)",
                             "Pause (yes vs. no)",
                             "Prob * Amount",
                             "Prob * Prev outcome",
                             "Amount * Prev outcome",
                             "Prob * Pause",
                             "Amount * Pause",
                             "Prev outcome * Pause",
                             "Prob * Amount * Prev outcome",
                             "Prob * Amount * Pause",
                             "Prob * Prev outcome * Pause",
                             "Amount * Prev outcome * Pause",
                             "Prob * Amount * Prev outcome * Pause"))
  )

prob_amount_post_plot <- draws %>%
  ggplot(aes(x = estimate, y = parameter)) +
  stat_halfeye() +
  geom_vline(xintercept = 0, linetype = "dashed") +
  labs(x = "Posterior distribution (log odds-ratio)", y = "")+
  scale_y_discrete(limits=rev) +
  theme(axis.text = element_text(size = 10, color = "black"),
        axis.title = element_text(size = 11))

prob_amount_post_plot

# another version with only a few variables of interest
param_selected <- c("Probability", "Prob * Prev outcome",
                    "Prob * Pause", "Amount",
                    "Amount * Prev outcome", "Amount * Pause")

prob_amount_post_selected_plot <- draws %>%
  filter(parameter %in% param_selected) %>%
  mutate(parameter = factor(parameter, levels = param_selected)) %>%
  ggplot(aes(x = estimate, y = parameter)) +
  stat_halfeye() +
  geom_vline(xintercept = 0, linetype = "dashed") +
  labs(x = "Posterior distribution (log odds-ratio)", y = "")+
  scale_y_discrete(limits=rev) +
  theme(axis.text = element_text(size = 10, color = "black"),
        axis.title = element_text(size = 11))

# save as a png file
ggsave(filename = "../5-plots/prob_amount_Exp4_complete.png", 
       prob_amount_post_plot,
       width = 7, height = 8)
```

```{r, results='asis'}
tab_model(fit_prob_amount)
```

#### Positive and negative EV ratios

For the choice RT, I analyzed trials with positive and negative EV ratios separately, and found diverging effects of EV ratios. Here I run a similar exploratory analysis on choices, on trials with positive and negative EV ratios separately.

```{r}
# get all trials with positive EV ratios
df_EV_pos <- df_exp_selected %>% filter(EV_ratio > 0)

# get the unique, positive EV ratios 
EV_ratio_pos <- df_EV_pos %>%
  .$EV_ratio %>% unique() %>% sort()

# compute the mean EV ratio
EV_ratio_pos_mean <- mean(EV_ratio_pos)

# center the EV ratio
df_EV_pos <- df_EV_pos %>%
  mutate(EV_ratio_c = EV_ratio - EV_ratio_pos_mean)

# fit the model
fit_EV_pos <- brm(
  game2_choose_HP ~ EV_ratio_c * game1_outcome_num * delay_num +
    (EV_ratio_c * game1_outcome_num * delay_num|subject_ID),
  family = bernoulli(link = "logit"),
  prior = 
    c(
      prior(normal(0, 2), class = Intercept),
      prior(normal(0, 1), class = b),
      prior(normal(0, 1), class = sd),
      prior(lkj(2), class = cor)
    ),
  data = df_EV_pos,
  cores = 4,
  iter = 15000,
  warmup = 5000,
  seed = 1234,
  file = "brms-fits/fit_EV_pos",
  backend = "cmdstanr"
)
```

Do the same for trials with negative EV ratios.

```{r}
# get all trials with negative EV ratios
df_EV_neg <- df_exp_selected %>% filter(EV_ratio < 0)

# get the unique, negative EV ratios 
EV_ratio_neg <- df_EV_neg %>%
  .$EV_ratio %>% unique() %>% sort()

# compute the mean EV ratio
EV_ratio_neg_mean <- mean(EV_ratio_neg)

# center the EV ratio
df_EV_neg <- df_EV_neg %>%
  mutate(EV_ratio_c = EV_ratio - EV_ratio_neg_mean)

# fit the model
fit_EV_neg <- brm(
  game2_choose_HP ~ EV_ratio_c * game1_outcome_num * delay_num +
    (EV_ratio_c * game1_outcome_num * delay_num|subject_ID),
  family = bernoulli(link = "logit"),
  prior = 
    c(
      prior(normal(0, 2), class = Intercept),
      prior(normal(0, 1), class = b),
      prior(normal(0, 1), class = sd),
      prior(lkj(2), class = cor)
    ),
  data = df_EV_neg,
  cores = 4,
  iter = 15000,
  warmup = 5000,
  seed = 1234,
  file = "brms-fits/fit_EV_neg",
  backend = "cmdstanr"
)
```

#### Absolute EV ratios

```{r}
df_exp_selected <- df_exp_selected %>%
  mutate(
    # decompose the EV ratio into two predictors,
    # its absolute value and its sign (positive vs. negative)
    EV_ratio_abs = abs(EV_ratio),
    EV_ratio_sign = ifelse(EV_ratio > 0, 0.5, -0.5),
    # determine whether the chosen option is the high EV one or not
    choose_high_EV_num = ifelse(choose_high_EV == "yes", 1, 0)
  )

# center the absolute EV ratio value
EV_ratio_abs <- df_exp_selected %>%
  .$EV_ratio_abs %>% unique()

EV_ratio_abs_mean <- mean(EV_ratio_abs)

df_exp_selected <- df_exp_selected %>%
  mutate(EV_ratio_abs_c = EV_ratio_abs - EV_ratio_abs_mean)

# fit a model
fit_EV_abs <- brm(
  choose_high_EV ~ EV_ratio_abs_c * EV_ratio_sign * game1_outcome_num * delay_num +
    (EV_ratio_abs_c * EV_ratio_sign * game1_outcome_num * delay_num|subject_ID),
  family = bernoulli(link = "logit"),
  prior = 
    c(
      prior(normal(0, 2), class = Intercept),
      prior(normal(0, 1), class = b),
      prior(normal(0, 1), class = sd),
      prior(lkj(2), class = cor)
    ),
  data = df_exp_selected,
  cores = 4,
  iter = 10000,
  warmup = 5000,
  seed = 1234,
  file = "brms-fits/fit_EV_abs",
  backend = "cmdstanr",
  control = list(adapt_delta = 0.9)
)
```

### Robustness check

As a robustness check, each time I use a different cutoff value for the LP-optimal catch trials, and repeat the analyses above.

```{r}
# to reduce the number of models,
# I fix the cut-off value for the HP-optimal catch trials to 9
# i.e., the pre-registered exclusion criterion
high_prob_cutoffs <- c(9)

low_prob_cutoffs <- df_catch_choices %>%
  filter(high_EV_option == "LP") %>%
  .$n_high_EV %>% unique()

# an empty tibble to hold all results
overall_summary <- tibble()

for (high_prob_cutoff in high_prob_cutoffs) {
  for (low_prob_cutoff in low_prob_cutoffs) {
    
    subject_exclude1 <- df_catch_choices %>%
      filter(
        high_EV_option == "HP",
        n_high_EV < high_prob_cutoff
      ) %>% .$subject_ID
    
    subject_exclude2 <- df_catch_choices %>%
      filter(
        high_EV_option == "LP",
        n_high_EV < low_prob_cutoff
      ) %>% .$subject_ID
    
    df_exp <- df_main %>%
      filter(
        !subject_ID %in% subject_exclude1,
        !subject_ID %in% subject_exclude2,
        trial_type == "exp"
      )
    
    # check the number of participants remaining
    n_subj <-  n_distinct(df_exp$subject_ID)
    
    # fit a brms model - go for the maximum random structure
    brms_file_name <- 
      paste("brms-fits/fit_exp_HP", 
            high_prob_cutoff, "LP", low_prob_cutoff, sep = "_")
    
    fit_HP_choice <- brm(
      game2_choose_HP ~ EV_ratio * game1_outcome_num * delay_num +
        (EV_ratio * game1_outcome_num * delay_num|subject_ID),
      family = bernoulli(link = "logit"),
      prior = 
        c(
          prior(normal(0, 2), class = Intercept),
          prior(normal(0, 1), class = b),
          prior(normal(0, 1), class = sd),
          prior(lkj(2), class = cor)
        ),
      data = df_exp,
      cores = 4,
      iter = 15000,
      warmup = 5000,
      seed = 1234,
      file = brms_file_name,
      backend = "cmdstanr"
    )
    
    # extract summary of the posterior draws
    post_summary <- 
      as_tibble(summary(fit_HP_choice)$fixed, rownames = NA) %>%
      rownames_to_column(var = "parameter") %>%
      mutate(
        n_subj = n_subj,
        HP_cutoff = high_prob_cutoff,
        LP_cutoff = low_prob_cutoff
      )
    
    # add it to the overall tibble
    overall_summary <- bind_rows(overall_summary, post_summary)
    
  }
}
```

```{r}
#| label: fig-robustness
#| fig-cap: Robustness check
#| fig-width: 6
#| fig-height: 8

# do some cleaning and reformatting of the variables
overall_summary_selected <- overall_summary %>%
  # no need to plot the Intercept, not informative
  filter(parameter != "Intercept") %>%
  mutate(
    # Re-code the labels so that it looks better
    param_label = 
      recode(parameter,
             "EV_ratio" = "EV Ratio",
             "game1_outcome_num" = "Previous Outcome",
             "delay_num" = "Pause",
             "EV_ratio:game1_outcome_num" = "EV Ratio * Previous Outcome",
             "EV_ratio:delay_num" = "EV Ratio * Pause",
             "game1_outcome_num:delay_num" = "Previous Outcome * Pause",
             "EV_ratio:game1_outcome_num:delay_num" = 
               "EV Ratio * Previous Outcome * Pause"),
    param_label = 
      factor(param_label,
             levels = c("Intercept",
                        "EV Ratio",
                        "Previous Outcome",
                        "Pause",
                        "EV Ratio * Previous Outcome",
                        "EV Ratio * Pause",
                        "Previous Outcome * Pause",
                        "EV Ratio * Previous Outcome * Pause")),
    # rename variables
    CI_upper = `u-95% CI`,
    CI_lower = `l-95% CI`
  )

# plot the posterior distributions from all models
robustness_plot <- overall_summary_selected %>%
  mutate(
    LP_cutoff = as.factor(LP_cutoff),
    HP_cutoff = as.factor(HP_cutoff)
  ) %>%
  ggplot(aes(LP_cutoff, Estimate, color = HP_cutoff)) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_point(position = position_dodge(width = 0.4)) +
  geom_errorbar(aes(ymin = CI_lower, ymax = CI_upper),
                width = 0.2, position = position_dodge(width = 0.4)) +
  facet_wrap(~param_label, ncol = 1, scales = "free_y") +
  labs(x = "Number of LP choices on LP-optimal trials",
       y = "Estimate (log odds-ratio)",
       color = "Number of HP choices on HP-optimal trials") 

robustness_plot

ggsave("../5-plots/robustness_Exp3.png", robustness_plot,
       width = 7, height = 9)

# generate a table for the number of participants left
# after applying each inclusion criterion
subj_count <- overall_summary %>%
  filter(parameter == "Intercept") %>%
  select(HP_cutoff, LP_cutoff, n_subj) %>%
  arrange(HP_cutoff, LP_cutoff) %>%
  # turn into the wide format
  pivot_wider(id_cols = HP_cutoff,
              names_from = LP_cutoff,
              values_from = n_subj)
```

## Between-exp comparisons

### With Experiment 2

Compare the current experiment with Experiment 2.

```{r}
# load the data from Experiment 2
df_exp2 <- read_csv("../../../../Exp2/data/processed/df_exp_exp2.csv")

# add experiment number, and adjust the subject ID
df_exp2 <- df_exp2 %>%
  mutate(
    Exp = "Exp2",
    subject_ID = paste0(Exp, subject_ID, sep = "_")
  )

# load the data from the current experiment again
df_exp4 <- read_csv("../../../data/processed/df_exp_exp4_complete.csv")

df_exp4 <- df_exp4 %>%
  mutate(
    Exp = "Exp4",
    subject_ID = paste0(Exp, subject_ID, sep = "_")
  )

# combine data from both experiments
df_exp2_exp4 <- df_exp2 %>%
  bind_rows(df_exp4) %>%
  mutate(Exp_num = ifelse(Exp == "Exp2", 0.5, -0.5))
```

```{r}
# fit a brms model
brms_file_name <- "brms-fits/fit_choice_exp2_exp4"

fit_choice_exp2_exp4 <- brm(
  game2_choose_HP ~ EV_ratio * game1_outcome_num * delay_num * Exp_num +
    (EV_ratio * game1_outcome_num * delay_num|subject_ID),
  family = bernoulli(link = "logit"),
  prior = 
    c(
      prior(normal(0, 2), class = Intercept),
      prior(normal(0, 1), class = b),
      prior(normal(0, 1), class = sd),
      prior(lkj(2), class = cor)
    ),
  data = df_exp2_exp4,
  cores = 4,
  iter = 15000,
  warmup = 5000,
  seed = 1234,
  file = brms_file_name,
  backend = "cmdstanr"
)
```

Again compare the current experiment with Experiment 2, but this time using probability and amount ratio as predictors.

```{r}
# compute the prob ratio and amount ratio between two options
df_exp2_exp3 <- df_exp2_exp3 %>%
  mutate(
    prob_ratio = (game2_HP_prob - game2_LP_prob)/(game2_HP_prob + game2_LP_prob) * 2,
    amount_ratio = (game2_HP_amount - game2_LP_amount)/(game2_HP_amount + game2_LP_amount) * 2
  )

# get the unique trials and compute the mean prob_ratio and amount_ratio
df_unique <- df_exp2_exp3 %>%
  select(game2_HP_prob, game2_HP_amount, game2_LP_prob, game2_LP_amount, prob_ratio, amount_ratio) %>%
  unique()

prob_ratio_mean <- mean(df_unique$prob_ratio)
amount_ratio_mean <- mean(df_unique$amount_ratio)

# center the prob_ratio and amount_ratio predictors
df_exp2_exp3 <- df_exp2_exp3 %>%
  mutate(
    prob_ratio_centered = prob_ratio - prob_ratio_mean,
    amount_ratio_centered = amount_ratio - amount_ratio_mean
  )

# fit a brms model
brms_file_name <- "brms-fits/fit_prob_amount_exp2_exp3"

fit_prob_amount_exp2_exp3 <- brm(
  game2_choose_HP ~ prob_ratio_centered * amount_ratio_centered *
                    game1_outcome_num * delay_num * Exp_num +
                    (prob_ratio_centered * amount_ratio_centered *
                    game1_outcome_num * delay_num|subject_ID),
  family = bernoulli(link = "logit"),
  prior = 
    c(
      prior(normal(0, 2), class = Intercept),
      prior(normal(0, 1), class = b),
      prior(normal(0, 1), class = sd),
      prior(lkj(2), class = cor)
    ),
  data = df_exp2_exp3,
  cores = 4,
  iter = 15000,
  warmup = 5000,
  seed = 1234,
  file = brms_file_name,
  backend = "cmdstanr"
)
```

### With Experiment 3

```{r}
# load the data from Experiment 3
df_exp3 <- read_csv("../../../../Exp3/data/processed/df_exp_exp3_complete.csv")

# add experiment number, and adjust the subject ID
df_exp3 <- df_exp3 %>%
  mutate(
    Exp = "Exp3",
    subject_ID = paste0(Exp, subject_ID, sep = "_")
  )

# load the data from the current experiment again
df_exp4 <- read_csv("../../../data/processed/df_exp_exp4_complete.csv")

df_exp4 <- df_exp4 %>%
  mutate(
    Exp = "Exp4",
    subject_ID = paste0(Exp, subject_ID, sep = "_")
  )

# combine data from both experiments
df_exp3_exp4 <- df_exp3 %>%
  bind_rows(df_exp4) %>%
  mutate(Exp_num = ifelse(Exp == "Exp3", 0.5, -0.5))
```

```{r}
# fit a brms model
brms_file_name <- "brms-fits/fit_choice_exp3_exp4"

fit_choice_exp3_exp4 <- brm(
  game2_choose_HP ~ EV_ratio * game1_outcome_num * delay_num * Exp_num +
    (EV_ratio * game1_outcome_num * delay_num|subject_ID),
  family = bernoulli(link = "logit"),
  prior = 
    c(
      prior(normal(0, 2), class = Intercept),
      prior(normal(0, 1), class = b),
      prior(normal(0, 1), class = sd),
      prior(lkj(2), class = cor)
    ),
  data = df_exp3_exp4,
  cores = 4,
  iter = 15000,
  warmup = 5000,
  seed = 1234,
  file = brms_file_name,
  backend = "cmdstanr"
)
```

Compare the current experiment with Experiment 1, with probability and amount ratios as predictors.

```{r}
# compute the prob ratio and amount ratio between two options
df_exp1_exp3 <- df_exp1_exp3 %>%
  mutate(
    prob_ratio = (game2_HP_prob - game2_LP_prob)/(game2_HP_prob + game2_LP_prob) * 2,
    amount_ratio = (game2_HP_amount - game2_LP_amount)/(game2_HP_amount + game2_LP_amount) * 2,
    prob_ratio_centered = prob_ratio - prob_ratio_mean,
    amount_ratio_centered = amount_ratio - amount_ratio_mean
  )

# fit a brms model
brms_file_name <- "brms-fits/fit_prob_amount_exp1_exp3"

fit_prob_amount_exp1_exp3 <- brm(
  game2_choose_HP ~ prob_ratio_centered * amount_ratio_centered *
                    game1_outcome_num * delay_num * Exp_num +
                    (prob_ratio_centered * amount_ratio_centered *
                    game1_outcome_num * delay_num|subject_ID),
  family = bernoulli(link = "logit"),
  prior = 
    c(
      prior(normal(0, 2), class = Intercept),
      prior(normal(0, 1), class = b),
      prior(normal(0, 1), class = sd),
      prior(lkj(2), class = cor)
    ),
  data = df_exp1_exp3,
  cores = 4,
  iter = 15000,
  warmup = 5000,
  seed = 1234,
  file = brms_file_name,
  backend = "cmdstanr"
)
```
